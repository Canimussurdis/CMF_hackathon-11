{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка LightGBM и Optuna - библиотеки для подбора гиперпараметров\n",
    "!pip install lightgbm optuna\n",
    "from lightgbm import LGBMRegressor\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиение на тренировочный, валидационный и тестовый наборы\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для определения гиперпараметров\n",
    "def objectives(trial):\n",
    "    params = {\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 300, 4000),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n",
    "            'max_bin': trial.suggest_int('max_bin', 2, 100),\n",
    "            'learning_rate': trial.suggest_uniform('learning_rate',0, 1),\n",
    "    }\n",
    "\n",
    "    model = LGBMRegressor(**params)\n",
    "    model.fit(X_train,y_train)\n",
    "    score = model.score(X_val,y_val) #r2_score\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поиск наилучшего набора гиперпараметров\n",
    "opt = optuna.create_study(direction='maximize',\n",
    "                          sampler=optuna.samplers.RandomSampler(seed=0))\n",
    "opt.optimize(objectives, n_trials=20)\n",
    "\n",
    "# Набор гиперпараметров с лучшим результатом на валидации \n",
    "trial = opt.best_trial\n",
    "params_best = dict(trial.params.items())\n",
    "params_best['random_seed'] = 42\n",
    "    \n",
    "# Предсказание с оптимальными гиперпараметрами на тестовой выборке\n",
    "model_o = LGBMRegressor(**params_best)\n",
    "model_o.fit(X_train,y_train)\n",
    "print('Коэффициент детерминации на тестовой выборке:')\n",
    "model_o.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# График с распределением feature importance\n",
    "feature_importances = (model_o.feature_importances_ / sum(model_o.feature_importances_)) * 100\n",
    "\n",
    "results = pd.DataFrame({'Features': X_train.columns,\n",
    "                        'Importances': feature_importances})\n",
    "results.sort_values(by='Importances', inplace=True)\n",
    "large = 20; med = 16; small = 12;\n",
    "params = {'axes.titlesize': large,\n",
    "          'figure.figsize': (13, 7),\n",
    "          'axes.labelsize': large,\n",
    "          'axes.titlesize': large,\n",
    "          'xtick.labelsize': large,\n",
    "          'ytick.labelsize': large,\n",
    "          'figure.titlesize': large}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "ax = plt.barh(results['Features'], results['Importances'])\n",
    "plt.xlabel('Importance percentages')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
